{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns                       #visualisation\n",
    "import matplotlib.pyplot as plt             #visualisation\n",
    "%matplotlib inline     \n",
    "sns.set(color_codes=True)\n",
    "\n",
    "#modeling\n",
    "\n",
    "from xgboost import XGBRegressor \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, LassoCV, RidgeCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, KFold, StratifiedGroupKFold, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "from sklearn import ensemble\n",
    "from sklearn import neighbors\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from math import sqrt\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM modeling\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from pandas import DataFrame , concat\n",
    "from sklearn.metrics import mean_absolute_error , mean_squared_error\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from numpy import mean , concatenate\n",
    "from math import sqrt\n",
    "from pandas import read_csv\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,LSTM,Activation\n",
    "from numpy import array , hstack\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "# if you're using google drive to store the dataset\n",
    "#from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/global/scratch/users/yaqiantang/discoveryData/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5th Site - US-Var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIMESTAMP_START</th>\n",
       "      <th>TIMESTAMP_END</th>\n",
       "      <th>TA_F</th>\n",
       "      <th>TA_F_QC</th>\n",
       "      <th>TA_ERA</th>\n",
       "      <th>SW_IN_POT</th>\n",
       "      <th>SW_IN_F</th>\n",
       "      <th>SW_IN_F_QC</th>\n",
       "      <th>SW_IN_ERA</th>\n",
       "      <th>LW_IN_F</th>\n",
       "      <th>...</th>\n",
       "      <th>NIRv</th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "      <th>b4</th>\n",
       "      <th>b5</th>\n",
       "      <th>b6</th>\n",
       "      <th>b7</th>\n",
       "      <th>IGBP</th>\n",
       "      <th>koppen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200011010000</td>\n",
       "      <td>200011010030</td>\n",
       "      <td>8.59</td>\n",
       "      <td>0</td>\n",
       "      <td>8.117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>297.554</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GRA</td>\n",
       "      <td>Temperate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200011010030</td>\n",
       "      <td>200011010100</td>\n",
       "      <td>8.54</td>\n",
       "      <td>0</td>\n",
       "      <td>7.898</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>297.554</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GRA</td>\n",
       "      <td>Temperate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200011010100</td>\n",
       "      <td>200011010130</td>\n",
       "      <td>8.51</td>\n",
       "      <td>0</td>\n",
       "      <td>7.680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>277.808</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GRA</td>\n",
       "      <td>Temperate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200011010130</td>\n",
       "      <td>200011010200</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0</td>\n",
       "      <td>7.353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>277.808</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GRA</td>\n",
       "      <td>Temperate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200011010200</td>\n",
       "      <td>200011010230</td>\n",
       "      <td>7.43</td>\n",
       "      <td>0</td>\n",
       "      <td>7.027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>277.808</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GRA</td>\n",
       "      <td>Temperate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TIMESTAMP_START  TIMESTAMP_END  TA_F  TA_F_QC  TA_ERA  SW_IN_POT  SW_IN_F  \\\n",
       "0     200011010000   200011010030  8.59        0   8.117        0.0      0.0   \n",
       "1     200011010030   200011010100  8.54        0   7.898        0.0      0.0   \n",
       "2     200011010100   200011010130  8.51        0   7.680        0.0      0.0   \n",
       "3     200011010130   200011010200  8.07        0   7.353        0.0      0.0   \n",
       "4     200011010200   200011010230  7.43        0   7.027        0.0      0.0   \n",
       "\n",
       "   SW_IN_F_QC  SW_IN_ERA  LW_IN_F  ...  NIRv  b1  b2  b3  b4  b5  b6  b7  \\\n",
       "0           0        0.0  297.554  ...   NaN NaN NaN NaN NaN NaN NaN NaN   \n",
       "1           0        0.0  297.554  ...   NaN NaN NaN NaN NaN NaN NaN NaN   \n",
       "2           0        0.0  277.808  ...   NaN NaN NaN NaN NaN NaN NaN NaN   \n",
       "3           0        0.0  277.808  ...   NaN NaN NaN NaN NaN NaN NaN NaN   \n",
       "4           0        0.0  277.808  ...   NaN NaN NaN NaN NaN NaN NaN NaN   \n",
       "\n",
       "   IGBP     koppen  \n",
       "0   GRA  Temperate  \n",
       "1   GRA  Temperate  \n",
       "2   GRA  Temperate  \n",
       "3   GRA  Temperate  \n",
       "4   GRA  Temperate  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "site_id = 'US-Var' # \n",
    "df = pd.read_csv(data_path + 'data_full_half_hourly_raw_v0_1_' + site_id + '.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TIMESTAMP_START', 'TIMESTAMP_END', 'TA_F', 'TA_F_QC', 'TA_ERA',\n",
       "       'SW_IN_POT', 'SW_IN_F', 'SW_IN_F_QC', 'SW_IN_ERA', 'LW_IN_F',\n",
       "       'LW_IN_F_QC', 'LW_IN_ERA', 'VPD_F', 'VPD_F_QC', 'VPD_ERA', 'P_F',\n",
       "       'P_F_QC', 'P_ERA', 'PA_F', 'PA_F_QC', 'PA_ERA', 'NETRAD', 'PPFD_IN',\n",
       "       'G_F_MDS', 'G_F_MDS_QC', 'LE_F_MDS', 'LE_F_MDS_QC', 'LE_CORR',\n",
       "       'H_F_MDS', 'H_F_MDS_QC', 'H_CORR', 'NEE_VUT_REF', 'NEE_VUT_REF_QC',\n",
       "       'NEE_CUT_REF', 'NEE_CUT_REF_QC', 'GPP_NT_VUT_REF', 'GPP_DT_VUT_REF',\n",
       "       'GPP_NT_CUT_REF', 'GPP_DT_CUT_REF', 'RECO_NT_VUT_REF',\n",
       "       'RECO_DT_VUT_REF', 'RECO_NT_CUT_REF', 'RECO_DT_CUT_REF', 'datetime',\n",
       "       'year', 'month', 'day', 'hour', 'SITE_ID', 'date', 'NEE_VUT_REF_qa',\n",
       "       'SW_DIF', 'EVI', 'NDVI', 'NIRv', 'b1', 'b2', 'b3', 'b4', 'b5', 'b6',\n",
       "       'b7', 'IGBP', 'koppen'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIMESTAMP_START</th>\n",
       "      <th>TIMESTAMP_END</th>\n",
       "      <th>TA_F</th>\n",
       "      <th>TA_F_QC</th>\n",
       "      <th>TA_ERA</th>\n",
       "      <th>SW_IN_POT</th>\n",
       "      <th>SW_IN_F</th>\n",
       "      <th>SW_IN_F_QC</th>\n",
       "      <th>SW_IN_ERA</th>\n",
       "      <th>LW_IN_F</th>\n",
       "      <th>...</th>\n",
       "      <th>NIRv</th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "      <th>b4</th>\n",
       "      <th>b5</th>\n",
       "      <th>b6</th>\n",
       "      <th>b7</th>\n",
       "      <th>IGBP</th>\n",
       "      <th>koppen</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-11-01 00:00:00</th>\n",
       "      <td>200011010000</td>\n",
       "      <td>200011010030</td>\n",
       "      <td>8.59</td>\n",
       "      <td>0</td>\n",
       "      <td>8.117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>297.554</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GRA</td>\n",
       "      <td>Temperate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-11-01 00:30:00</th>\n",
       "      <td>200011010030</td>\n",
       "      <td>200011010100</td>\n",
       "      <td>8.54</td>\n",
       "      <td>0</td>\n",
       "      <td>7.898</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>297.554</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GRA</td>\n",
       "      <td>Temperate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-11-01 01:00:00</th>\n",
       "      <td>200011010100</td>\n",
       "      <td>200011010130</td>\n",
       "      <td>8.51</td>\n",
       "      <td>0</td>\n",
       "      <td>7.680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>277.808</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GRA</td>\n",
       "      <td>Temperate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-11-01 01:30:00</th>\n",
       "      <td>200011010130</td>\n",
       "      <td>200011010200</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0</td>\n",
       "      <td>7.353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>277.808</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GRA</td>\n",
       "      <td>Temperate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-11-01 02:00:00</th>\n",
       "      <td>200011010200</td>\n",
       "      <td>200011010230</td>\n",
       "      <td>7.43</td>\n",
       "      <td>0</td>\n",
       "      <td>7.027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>277.808</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GRA</td>\n",
       "      <td>Temperate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     TIMESTAMP_START  TIMESTAMP_END  TA_F  TA_F_QC  TA_ERA  \\\n",
       "datetime                                                                     \n",
       "2000-11-01 00:00:00     200011010000   200011010030  8.59        0   8.117   \n",
       "2000-11-01 00:30:00     200011010030   200011010100  8.54        0   7.898   \n",
       "2000-11-01 01:00:00     200011010100   200011010130  8.51        0   7.680   \n",
       "2000-11-01 01:30:00     200011010130   200011010200  8.07        0   7.353   \n",
       "2000-11-01 02:00:00     200011010200   200011010230  7.43        0   7.027   \n",
       "\n",
       "                     SW_IN_POT  SW_IN_F  SW_IN_F_QC  SW_IN_ERA  LW_IN_F  ...  \\\n",
       "datetime                                                                 ...   \n",
       "2000-11-01 00:00:00        0.0      0.0           0        0.0  297.554  ...   \n",
       "2000-11-01 00:30:00        0.0      0.0           0        0.0  297.554  ...   \n",
       "2000-11-01 01:00:00        0.0      0.0           0        0.0  277.808  ...   \n",
       "2000-11-01 01:30:00        0.0      0.0           0        0.0  277.808  ...   \n",
       "2000-11-01 02:00:00        0.0      0.0           0        0.0  277.808  ...   \n",
       "\n",
       "                     NIRv  b1  b2  b3  b4  b5  b6  b7  IGBP     koppen  \n",
       "datetime                                                                \n",
       "2000-11-01 00:00:00   NaN NaN NaN NaN NaN NaN NaN NaN   GRA  Temperate  \n",
       "2000-11-01 00:30:00   NaN NaN NaN NaN NaN NaN NaN NaN   GRA  Temperate  \n",
       "2000-11-01 01:00:00   NaN NaN NaN NaN NaN NaN NaN NaN   GRA  Temperate  \n",
       "2000-11-01 01:30:00   NaN NaN NaN NaN NaN NaN NaN NaN   GRA  Temperate  \n",
       "2000-11-01 02:00:00   NaN NaN NaN NaN NaN NaN NaN NaN   GRA  Temperate  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'GPP_NT_VUT_REF'\n",
    "features = ['year','TA_ERA','SW_IN_ERA','P_ERA','VPD_ERA','b1','b2','b3','b4','b5','b6',\n",
    "            'b7','NDVI','EVI','NIRv']\n",
    "# and categorical features: IGBP and koppen\n",
    "\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "df = df.set_index('datetime')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['GPP_NT_VUT_REF', 'year', 'TA_ERA', 'SW_IN_ERA', 'P_ERA', 'VPD_ERA',\n",
       "       'b1', 'b2', 'b3', 'b4', 'b5', 'b6', 'b7', 'NDVI', 'EVI', 'NIRv',\n",
       "       'IGBP_GRA', 'koppen_Temperate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One hot encoding categorical variables: IGBP and Koppen\n",
    "df_ohe = df[[target, 'IGBP', 'koppen'] + features]\n",
    "\n",
    "categorical_columns = ['IGBP', 'koppen']\n",
    "for col in categorical_columns:\n",
    "    col_ohe = pd.get_dummies(df[col], prefix=col)\n",
    "    df_ohe = pd.concat((df_ohe, col_ohe), axis=1).drop(col, axis=1)\n",
    "\n",
    "df_ohe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset(df):\n",
    "    assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n",
    "    df.dropna(inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GPP_NT_VUT_REF</th>\n",
       "      <th>year</th>\n",
       "      <th>TA_ERA</th>\n",
       "      <th>SW_IN_ERA</th>\n",
       "      <th>P_ERA</th>\n",
       "      <th>VPD_ERA</th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "      <th>b4</th>\n",
       "      <th>b5</th>\n",
       "      <th>b6</th>\n",
       "      <th>b7</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>EVI</th>\n",
       "      <th>NIRv</th>\n",
       "      <th>IGBP_GRA</th>\n",
       "      <th>koppen_Temperate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001-01-01 00:00:00</th>\n",
       "      <td>-1.84180</td>\n",
       "      <td>2001</td>\n",
       "      <td>2.171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.0628</td>\n",
       "      <td>0.2694</td>\n",
       "      <td>0.0304</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.3155</td>\n",
       "      <td>0.2595</td>\n",
       "      <td>0.1311</td>\n",
       "      <td>0.621915</td>\n",
       "      <td>0.364194</td>\n",
       "      <td>0.167544</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-01 00:30:00</th>\n",
       "      <td>-1.91023</td>\n",
       "      <td>2001</td>\n",
       "      <td>2.161</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.107</td>\n",
       "      <td>0.0628</td>\n",
       "      <td>0.2694</td>\n",
       "      <td>0.0304</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.3155</td>\n",
       "      <td>0.2595</td>\n",
       "      <td>0.1311</td>\n",
       "      <td>0.621915</td>\n",
       "      <td>0.364194</td>\n",
       "      <td>0.167544</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-01 01:00:00</th>\n",
       "      <td>-1.85277</td>\n",
       "      <td>2001</td>\n",
       "      <td>2.150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.321</td>\n",
       "      <td>0.0628</td>\n",
       "      <td>0.2694</td>\n",
       "      <td>0.0304</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.3155</td>\n",
       "      <td>0.2595</td>\n",
       "      <td>0.1311</td>\n",
       "      <td>0.621915</td>\n",
       "      <td>0.364194</td>\n",
       "      <td>0.167544</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-01 01:30:00</th>\n",
       "      <td>-5.84140</td>\n",
       "      <td>2001</td>\n",
       "      <td>2.044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.391</td>\n",
       "      <td>0.0628</td>\n",
       "      <td>0.2694</td>\n",
       "      <td>0.0304</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.3155</td>\n",
       "      <td>0.2595</td>\n",
       "      <td>0.1311</td>\n",
       "      <td>0.621915</td>\n",
       "      <td>0.364194</td>\n",
       "      <td>0.167544</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-01 02:00:00</th>\n",
       "      <td>-2.51478</td>\n",
       "      <td>2001</td>\n",
       "      <td>1.938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.461</td>\n",
       "      <td>0.0628</td>\n",
       "      <td>0.2694</td>\n",
       "      <td>0.0304</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.3155</td>\n",
       "      <td>0.2595</td>\n",
       "      <td>0.1311</td>\n",
       "      <td>0.621915</td>\n",
       "      <td>0.364194</td>\n",
       "      <td>0.167544</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     GPP_NT_VUT_REF  year  TA_ERA  SW_IN_ERA  P_ERA  VPD_ERA  \\\n",
       "datetime                                                                       \n",
       "2001-01-01 00:00:00        -1.84180  2001   2.171        0.0    0.0    0.893   \n",
       "2001-01-01 00:30:00        -1.91023  2001   2.161        0.0    0.0    1.107   \n",
       "2001-01-01 01:00:00        -1.85277  2001   2.150        0.0    0.0    1.321   \n",
       "2001-01-01 01:30:00        -5.84140  2001   2.044        0.0    0.0    1.391   \n",
       "2001-01-01 02:00:00        -2.51478  2001   1.938        0.0    0.0    1.461   \n",
       "\n",
       "                         b1      b2      b3      b4      b5      b6      b7  \\\n",
       "datetime                                                                      \n",
       "2001-01-01 00:00:00  0.0628  0.2694  0.0304  0.0625  0.3155  0.2595  0.1311   \n",
       "2001-01-01 00:30:00  0.0628  0.2694  0.0304  0.0625  0.3155  0.2595  0.1311   \n",
       "2001-01-01 01:00:00  0.0628  0.2694  0.0304  0.0625  0.3155  0.2595  0.1311   \n",
       "2001-01-01 01:30:00  0.0628  0.2694  0.0304  0.0625  0.3155  0.2595  0.1311   \n",
       "2001-01-01 02:00:00  0.0628  0.2694  0.0304  0.0625  0.3155  0.2595  0.1311   \n",
       "\n",
       "                         NDVI       EVI      NIRv  IGBP_GRA  koppen_Temperate  \n",
       "datetime                                                                       \n",
       "2001-01-01 00:00:00  0.621915  0.364194  0.167544         1                 1  \n",
       "2001-01-01 00:30:00  0.621915  0.364194  0.167544         1                 1  \n",
       "2001-01-01 01:00:00  0.621915  0.364194  0.167544         1                 1  \n",
       "2001-01-01 01:30:00  0.621915  0.364194  0.167544         1                 1  \n",
       "2001-01-01 02:00:00  0.621915  0.364194  0.167544         1                 1  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean the data.\n",
    "df = clean_dataset(df_ohe)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into training and testing\n",
    "Data = df[features + [target]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import binascii\n",
    "def test_set_check(identifier, test_ratio):\n",
    "    return binascii.crc32(np.int64(hash(identifier))) & 0xffffffff < test_ratio * 2**32\n",
    "\n",
    "# Function to split train/test\n",
    "def split_train_test_by_id(data, test_ratio, id_column):\n",
    "    ids = data[id_column]\n",
    "    print(ids)\n",
    "    in_test_set = ids.apply(lambda id_: test_set_check(id_, test_ratio))\n",
    "    return data.loc[~in_test_set], data.loc[in_test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime\n",
      "2001-01-01 00:00:00    2001\n",
      "2001-01-01 00:30:00    2001\n",
      "2001-01-01 01:00:00    2001\n",
      "2001-01-01 01:30:00    2001\n",
      "2001-01-01 02:00:00    2001\n",
      "                       ... \n",
      "2014-12-31 21:30:00    2014\n",
      "2014-12-31 22:00:00    2014\n",
      "2014-12-31 22:30:00    2014\n",
      "2014-12-31 23:00:00    2014\n",
      "2014-12-31 23:30:00    2014\n",
      "Name: year, Length: 238752, dtype: int64\n",
      "(153936, 16) (84816, 16)\n"
     ]
    }
   ],
   "source": [
    "test, train = split_train_test_by_id(Data, 0.7, \"year\")\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[features + [target]]\n",
    "\n",
    "test = test[features + [target]]\n",
    "\n",
    "data = Data[features + [target]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data = np.vstack((train, test))\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "train_scaled = data_scaled[:11116,]\n",
    "test_scaled = data_scaled[11116:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X.shape (1, 12, 15)\n",
      "train_y.shape (1, 11)\n",
      "test_X.shape (1, 12, 15)\n",
      "test_y.shape (1, 11)\n"
     ]
    }
   ],
   "source": [
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out-1\n",
    "  # check if we are beyond the dataset\n",
    "        if out_end_ix > len(sequences):\n",
    "            break\n",
    "  # gather input and output parts of the pattern\n",
    "    seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1:out_end_ix, -1]\n",
    "    X.append(seq_x)\n",
    "    y.append(seq_y)\n",
    "    return array(X), array(y)\n",
    "\n",
    "# choose a number of time steps #change this accordingly\n",
    "n_steps_in, n_steps_out = 12, 12\n",
    "# covert into input/output\n",
    "train_X, train_y = split_sequences(train_scaled, n_steps_in, n_steps_out)\n",
    "test_X, test_y = split_sequences(test_scaled, n_steps_in, n_steps_out)\n",
    "\n",
    "print (\"train_X.shape\" , train_X.shape) \n",
    "print (\"train_y.shape\" , train_y.shape)\n",
    "print (\"test_X.shape\" , test_X.shape) \n",
    "print (\"test_y.shape\" , test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer learning rate\n",
    "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(n_steps_in, 15)))\n",
    "model.add(LSTM(50, activation='relu'))\n",
    "model.add(Dense(n_steps_out))\n",
    "model.add(Activation('linear'))\n",
    "model.compile(loss='mse' , optimizer=opt , metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_12 (LSTM)              (None, 12, 15)            1860      \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 15)                1860      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 12)                192       \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 12)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,912\n",
      "Trainable params: 3,912\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/global/scratch/users/yaqiantang/conda/ml/lib/python3.10/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/global/scratch/users/yaqiantang/conda/ml/lib/python3.10/site-packages/keras/engine/training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/global/scratch/users/yaqiantang/conda/ml/lib/python3.10/site-packages/keras/engine/training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"/global/scratch/users/yaqiantang/conda/ml/lib/python3.10/site-packages/keras/engine/training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"/global/scratch/users/yaqiantang/conda/ml/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/global/scratch/users/yaqiantang/conda/ml/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_7\" is incompatible with the layer: expected shape=(None, 12, 15), found shape=(1, 16)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [67]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/global/scratch/users/yaqiantang/conda/ml/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filefjm4o5ey.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/global/scratch/users/yaqiantang/conda/ml/lib/python3.10/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/global/scratch/users/yaqiantang/conda/ml/lib/python3.10/site-packages/keras/engine/training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/global/scratch/users/yaqiantang/conda/ml/lib/python3.10/site-packages/keras/engine/training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"/global/scratch/users/yaqiantang/conda/ml/lib/python3.10/site-packages/keras/engine/training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"/global/scratch/users/yaqiantang/conda/ml/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/global/scratch/users/yaqiantang/conda/ml/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_7\" is incompatible with the layer: expected shape=(None, 12, 15), found shape=(1, 16)\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, batch_size=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredict = model.predict(train_X)\n",
    "testPredict = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainScore = np.sqrt(mean_squared_error(train_y, trainPredict))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = np.sqrt(mean_squared_error(test_y, testPredict))\n",
    "print('Test Score: %.2f RMSE' % (testScore))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
